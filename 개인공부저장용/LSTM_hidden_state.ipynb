{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFs1Lngf9PMF"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "nums = [0]"
      ],
      "metadata": {
        "id": "L3osJFO9-QDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_time_series(iter):\n",
        "    nums= [0]\n",
        "    \n",
        "    for _ in range(iter):\n",
        "        for i in range(10):\n",
        "            nums.append(nums[-1]+np.random.normal(5,1))\n",
        "        for i in range(10):\n",
        "            nums.append(nums[-1]-np.random.normal(5,1))\n",
        "    return np.array(nums)[1:]"
      ],
      "metadata": {
        "id": "j8P5P8wduEFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_array = make_time_series(100)\n",
        "num_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aD7aN-2SAsa",
        "outputId": "19da02e1-a335-415f-f6f7-d54f577e2af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_array = num_array.reshape((-1, 10))\n",
        "num_array = num_array[:,:, np.newaxis]\n",
        "\n",
        "num_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAloObsTVAOx",
        "outputId": "8da1d1ba-c95b-4e09-9d9e-a0524c5382b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_input = num_array[:num_array.shape[0]-1]\n",
        "dec_target, dec_input = num_array[1:],num_array[1:]\n",
        "enc_input.shape, dec_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-hNyMh9VcC5",
        "outputId": "38899b93-1837-4337-caa2-8fe60bc52de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((199, 10, 1), (199, 10, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.layers.Input(shape=(10, 1), name=\"encoder_input\")\n",
        "encoder_lstm = keras.layers.LSTM(units=64, \n",
        "                                 return_state=True,\n",
        "                                 name=\"encoder_lstm\")\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "ilECzkyOSOyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = keras.layers.Input(shape=(None,1),\n",
        "                                    name=\"decoder_input\")\n",
        "\n",
        "decoder_lstm = keras.layers.LSTM(units=64, \n",
        "                                 return_sequences=True, \n",
        "                                 return_state=True,                             \n",
        "                                 name=\"decoder_lstm\")\n",
        "  \n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs, \n",
        "                                                                 initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = keras.layers.TimeDistributed(keras.layers.Dense(1))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "4H6-aZ0Feyui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model([encoder_inputs,decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")"
      ],
      "metadata": {
        "id": "RrF-tpUGhHkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpIwLC3ehI70",
        "outputId": "ae23ac03-dcbd-4a71-e81d-187a6a453b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " encoder_lstm (LSTM)            [(None, 64),         16896       ['encoder_input[0][0]']          \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)            [(None, None, 64),   16896       ['decoder_input[0][0]',          \n",
            "                                 (None, 64),                      'encoder_lstm[0][1]',           \n",
            "                                 (None, 64)]                      'encoder_lstm[0][2]']           \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, None, 1)     65          ['decoder_lstm[0][0]']           \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 33,857\n",
            "Trainable params: 33,857\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "return_sequence는 return_sequences=True로 설정하면 RNN 층의 출력이 시퀀스로 반환되므로 다음 RNN 층의 입력으로 사용됩니다. 이렇게 하면 이전 타임스텝에서 계산된 출력을 현재 타임스텝의 입력으로 사용할 수 있으므로 모델이 더욱 정확하게 예측을 수행할 수 있습니다. 이를 교사 강요(teacher forcing)라고 합니다.\n",
        "\n",
        "https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=chunjein&logNo=221589624838\n",
        "\n",
        "만약 return_sequences=False로 설정하면 RNN 층의 출력이 마지막 타임스텝의 출력만 반환되므로, 다음 층의 입력으로는 마지막 타임스텝의 출력만 사용됩니다. 이는 일반적으로 sequence-to-sequence 모델에서 디코더 층에서만 사용됩니다.\n",
        "\n",
        "최종 출력 층인 dense층을 time_distributed 층으로 감싸주는 이유는 매 타입스텝마다 발생하는 손실을 반영하기 위함이다. "
      ],
      "metadata": {
        "id": "hONi0MAXHQW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x=[enc_input, dec_input],\n",
        "    y=dec_target,\n",
        "    epochs=10\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5ATbM1nhxt-",
        "outputId": "f3d1f470-2a02-4749-cca5-050cfab2712d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 5s 13ms/step - loss: 401.4518\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 381.3730\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 361.8965\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 342.2415\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 321.8994\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 301.5331\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 284.0751\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 268.6053\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 254.9967\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 242.6561\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59255c3490>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict([enc_input,dec_input])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyUKNIwdiIIt",
        "outputId": "360cac0b-4bf4-4b84-a039-98b393623a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict([enc_input[0][np.newaxis,:,:], dec_input[0][np.newaxis,:,:]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCHawEkRlOTv",
        "outputId": "152e047e-8624-4789-b99a-7f00a6555a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.ones(shape=(1, 10, 1))\n",
        "_, state_h_value, _ = encoder_lstm(input_data)\n",
        "state_h_value_numpy = state_h_value.numpy()\n",
        "print(state_h_value_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjIHcx0L1H42",
        "outputId": "6d4ca615-ed22-4e8c-fbee-6349dc8ad06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33372492]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30mSzko8pmD",
        "outputId": "62551386-afff-4a64-8075-8ad93e94fa54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(model.get_weights())):\n",
        "    print(model.get_weights()[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoULFNL-EYyQ",
        "outputId": "f54619cc-9596-45dd-9bc3-9884922feeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4)\n",
            "(1, 4)\n",
            "(4,)\n",
            "(1, 4)\n",
            "(1, 4)\n",
            "(4,)\n",
            "(1, 1)\n",
            "(1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 가중치는 LSTM 셀이 하나일때 나타나는 가중치 개수이다. \n",
        "\n",
        "각각\n",
        "- encoder_lstm의 입력 가중치\n",
        "- encoder_lstm의 숨겨진 상태 가중치\n",
        "- encoder_lstm의 편향 가중치\n",
        "- decoder_lstm의 입력 가중치\n",
        "- decoder_lstm의 숨겨진 상태 가중치\n",
        "- decoder_lstm의 편향 가중치\n",
        "- decoder_dense의 가중치\n",
        "- decoder_dense의 편향 가중치\n",
        "이다. \n",
        "\n",
        "각각의 RNN셀들은 각 타임스텝에서 다음 타임스텝으로 넘어갈 때 완전히 연결된다. LSRM은 내부적으로 4개의 가중치가 있기 때문에 4라는 수치를 볼 수 있다."
      ],
      "metadata": {
        "id": "3RmG740AGRSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer 공부를 하다가 RNN의 동작 원리가 헷갈려서 다시 공부했다. \n",
        "\n",
        "내가 만든 모델은 seq2seq모델이고 디코더에 입력을 넣어서 교사강요 방식으로 학습이 진행된다. \n",
        "\n",
        "그렇기 때문에 학습시와 예측시의 모델 작동이 다르게 이루어진다. (이부분은 아직 모르겠음)\n",
        "\n",
        "굳이 encoder-decoder로 나누지 않고, many to one 방식으로 만들수도 있다. 그러면 바로 다음 타임스텝값을 예측하는 모델이 만들어 지는 것이다. \n",
        "\n",
        "또한 이번 실습을 통해서 rnn 셀을 연결과 가중치에 대해서 간단하게 알 수 있었다.\n",
        "\n",
        "\n",
        "하지만 궁금한 점이 하나가 있는데, LSTM셀이 잘 작동하고 어떻게 사용하는지 간단하게 알았지만 정확히 어떻게 내부적으로 동작하는지는 잘 모르겠다. \n",
        "\n",
        "4개의 게이트가 어떻게 작동하는 건지는 잘모르겠다는 말이다. 이부분은 그냥 내가 공부를 덜 해서 그런건지 아니면 그냥 모델이 블랙박스로 이루어졌기 떄문인지 잘 모르겠다. \n",
        "\n",
        "내가 왜 내부적인 작동을 알고 싶냐면 내부적인 작동을 알고 시계열 데이터에 학습이 어떻게 진행되는 지 궁금하기 떄문이다. 만약 큰 급등이 있고 차차 하락하는 시계열 데이터라면 큰 급등을 장기적으로 기억하는 것인지... 이런 부분이 궁금하다. 암튼 이부분은 천천히 고민해봐야할듯하다. "
      ],
      "metadata": {
        "id": "3PCU7Fz-HPEo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrLJYYuQJVsK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}