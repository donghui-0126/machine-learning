{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb211aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpyNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.23.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "scipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.23.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a092351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3be671",
   "metadata": {},
   "source": [
    "# 선형 오토인코더로 PCA 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbeda202",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "# 3D 데이터 만들기\n",
    "\n",
    "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
    "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "    data = np.empty((m, 3))\n",
    "    data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
    "    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
    "    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
    "    return data\n",
    "\n",
    "X_train = generate_3d_data(60)\n",
    "X_train = X_train - X_train.mean(axis=0, keepdims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915c1a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e462c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "encoder = keras.models.Sequential([keras.laye# 과소완전 선형 오토인코더로 PCA 수행하기rs.Dense(2, input_shape=[3])])\n",
    "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
    "\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85024958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.2845\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1801\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1213\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0860\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0639\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0498\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0401\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0338\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0292\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0260\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0222\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0210\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0201\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0181\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0177\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs=20)\n",
    "codings = encoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe96c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5dce98",
   "metadata": {},
   "source": [
    "**3D 데이터를 가장 잘 투영하는 최상의 평면을 찾는 과정이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0be80",
   "metadata": {},
   "source": [
    "# 적층 오토인코더\n",
    "오토인코더도 다른 신경망과 마찬가지로 여러 은닉층을 가질 수 있다. 이런 경우를 stacked autoencoder(적층 오토인코더) 라고 한다.\n",
    "\n",
    "그러나 오토인코더가 너무 강력해지지 않도록 조심해야한다. 오토인코더가 너무 강력해진다면 일반화 성능이 굉장히 낮아질 것 이기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69dcb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist 데이터셋을 사용한다.\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcb984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3371 - val_loss: 0.3106\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.3049 - val_loss: 0.3068\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.2980 - val_loss: 0.2969\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.2940 - val_loss: 0.2944\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2916 - val_loss: 0.2916\n",
      "Epoch 6/10\n",
      "1078/1719 [=================>............] - ETA: 4s - loss: 0.2903"
     ]
    }
   ],
   "source": [
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(30, activation=\"selu\")\n",
    "])\n",
    "\n",
    "stacked_decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(28*28, activation='sigmoid'),\n",
    "    keras.layers.Reshape([28,28])\n",
    "])\n",
    "\n",
    "\n",
    "# 재구성 작업을 할 때 BCE를 손실함수로 사용하는 이유는 픽셀이 검정일 확률을 찾는 것이기 때문이다.\n",
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "stacked_ae.compile(loss='binary_crossentropy',\n",
    "                  optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
    "\n",
    "stacked_ae.fit(X_train, X_train, epochs=10,\n",
    "              validation_data=(X_valid, X_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
