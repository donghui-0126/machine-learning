{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40903730",
   "metadata": {},
   "source": [
    "휴학을 하고 여러 공부를 했다.\n",
    "\n",
    "나의 휴학 목표는 소프트웨어융합학과 복수전공을 내년 상반기에 시작하는 것 + 코딩공부가 향상이기 때문에 내가 관심있는 머신러닝 분야를 많이 공부했다. \n",
    "\n",
    "지금까지 한 공부로는\n",
    "1. 코드잇 머신러닝을 통한 머신러닝 공부\n",
    "2. 위에 공부에서 부족함을 느껴서 [파이썬 머신러닝 완벽가이드](https://github.com/donghui-0126/machine-learning/tree/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C)책을 이용한 머신러닝 공부\n",
    "3. \\[[카페 사진 감성 분석](https://github.com/donghui-0126/mini-project/tree/main/%EC%B9%B4%ED%8E%98%20%EC%82%AC%EC%A7%84%20%EA%B0%90%EC%84%B1%20%EB%B6%84%EC%84%9D)\\]프로젝트\n",
    "\n",
    "를 했다. \n",
    "\n",
    "\n",
    "이 공부를 하고 다음 공부를 무엇을 할 지 후보를 정해봤다. \n",
    "- 머신러닝을 좀더 자세하게 공부하기\n",
    "- 딥러닝에 대해서 공부하기\n",
    "- html/css/javascript(웹) 공부하기\n",
    "- django 라이브러리 공부하기\n",
    "가 후보 군에 있었는데, 나는 딥러닝을 공부해보고 싶었다.\n",
    "\n",
    "그 이유는 전에 dacon에서 진행되는 머신러닝 대회([청경채 성장 분석](https://dacon.io/competitions/official/235961/codeshare/6021?page=1&dtype=recent))를 하려고 했다.<br>\n",
    "그때 나는 내가 배운 머신러닝으로 작성할 엄두안났는데(물론 나의 머신러닝실력도 하찮지만..) 예제 코드를 보니 딥러닝 기법을 사용한 코드가 적혀있었다. \n",
    "\n",
    "그것을 보고 충격을 받아서 딥러닝도 공부하기로 결심했다. 꼭 그거 때문만은 아니고 재밌어 보여서도 있다! ㅎㅎ ~~공부n일차: 상당히 재미지다.~~\n",
    "\n",
    "딥러닝은 10장 11장 12장을 공부하고 다시 머신러닝을 공부할 생각이다. \n",
    "\n",
    "아마 머신러닝의 추가적인 공부/프로젝트/웹/django(백엔드) 공부를 병행할 것 같다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55aea2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533e71b",
   "metadata": {},
   "source": [
    "이제 본격적인 공부를 시작할 건데, 나는 핸즈온 머신러닝 으로 공부하기로 했다.\n",
    "\n",
    "이 책이 좋다고 하던데 마침 전공책으로도 쓰여서 미리 봐두면 좋을 것 같기 때문이다. \n",
    "\n",
    "책에다 밑줄을 그으면서 공부하기 때문에, 여기는 굉장히 중요하다는 개념이나 코드들만 적힐 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d881af",
   "metadata": {},
   "source": [
    "-----------\n",
    "이전에 간단하게 공부했던 deep-leraning 정리본 링크이다.<br>\n",
    "https://github.com/donghui-0126/machine-learning/tree/main/deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71964f26",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fa119",
   "metadata": {},
   "source": [
    "### 연습문제 1 \n",
    "https://playground.tensorflow.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed581f",
   "metadata": {},
   "source": [
    "### 텐서플로우 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48128f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a004269",
   "metadata": {},
   "source": [
    "### 케라스를 사용해서 데이터셋 적재하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26ddbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist= keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f98e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape\n",
    "# 784크기(1d)로 데이터가 나열된 사이킷런의 mnist데이터(matrix)와 다르게 28x28 배열로 이루어짐(tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14bfd067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04acdb",
   "metadata": {},
   "source": [
    "### 트레인셋을 검정셋과 트레인셋으로 나누고 0~1사이의 범위로 스케일 변환\n",
    "검증셋이 없으면 트레인셋에 대한 과대적합이 일어날 수도 있기 때문에 유의해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2057cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab827841",
   "metadata": {},
   "source": [
    "### class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7e473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \" Shirt\",\"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860cb2b",
   "metadata": {},
   "source": [
    "### 시퀀셜 API를 사용해서 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a3fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential 모델을 만든다. 이 모델을 가장 간단한 케라스의 신경망 모델이다.\n",
    "#순서대로 연결된 층을 일렬로 쌓아서 구성한다.\n",
    "model = keras.models.Sequential() \n",
    "\n",
    "# 첫번째 층을 만들고 모델에 추가함. Flatten층은 입력이미지를 1D 배열로 변환한다. \n",
    "# 즉, 입력 데이터 X를 받으면 X.reshape(-1, 28*28)을 계산한다. 이층은 모델 파라미터를 가지지 않고, 간단한 전처리만 수행한다.\n",
    "# 모델의 첫번째 층이므로 input_shape를 지정해야한다. 여기에는 배치 크기를 제외한 샘플의 크기만 써야한다. \n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "\n",
    "# 뉴런 300개를 가진 Dense 은닉층을 추가한다. 이 층의 활성화 함수는 ReLU가 사용된다. \n",
    "# Dense층 마다 각자 가중치행렬을 관리한다. 이 행렬에는 뉴런과 입력 사이의 모든 연결 가중치가 포함된다. \n",
    "# 또한 뉴런마다 하나씩 있는 편향도 벡터로 관리한다.\n",
    "model.add(keras.layers.Dense(300,activation='relu'))\n",
    "\n",
    "# 다음층도 뉴런 100개를 가진 활성화 함수가 ReLU인 Dense은닉층을 추가한다.\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "\n",
    "# 마지막으로 뉴런 10개를 가진 Dense층을 추가한다. 배타적인 클래스이기 때문에 soft_max함수를 사용한다.\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fbdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 같은 코드를 다른 방식으로 작성하는 코드이다.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7931bee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# dense_6은 784 * 300 (가중치 개수) + 300 (편향개수) =235500 만큼의 파라미터를 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858145a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x20b92aebe50>,\n",
       " <keras.layers.core.dense.Dense at 0x20b92aebfd0>,\n",
       " <keras.layers.core.dense.Dense at 0x20b92aebd60>,\n",
       " <keras.layers.core.dense.Dense at 0x20b93099b50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963283a1",
   "metadata": {},
   "source": [
    "### 각 층에 인덱스로 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faeda482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57c9e3",
   "metadata": {},
   "source": [
    "### 각 층의 가중치과 편향을 얻는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcbb2c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00421565, -0.00351667,  0.05101556, ..., -0.0108448 ,\n",
       "         0.01602399, -0.03167915],\n",
       "       [ 0.00324626,  0.01552586,  0.04142319, ..., -0.07091267,\n",
       "        -0.02079091, -0.00040959],\n",
       "       [ 0.02905273, -0.05547583,  0.03890333, ..., -0.04754068,\n",
       "         0.01252925,  0.03921711],\n",
       "       [-0.05560946, -0.05324187, -0.03196876, ...,  0.07071427,\n",
       "         0.04005713,  0.0312743 ],\n",
       "       [ 0.01593808, -0.02285301, -0.04381575, ...,  0.04904685,\n",
       "        -0.03033808,  0.03853341]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, b = hidden1.get_weights()\n",
    "print(W.shape)\n",
    "W[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5d26f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b.shape)\n",
    "b[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec681b84",
   "metadata": {},
   "source": [
    "### 모델 컴파일\n",
    "사용할 손실함수와 옵티마이저를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6da2e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f29a39",
   "metadata": {},
   "source": [
    "위 코드에 대한 설명이 필요할 것 같다.\n",
    "\n",
    "위 코드에서 클래스가 배타적이므로 sparse_categorical_crossentropy 를 사용한다. <br>\n",
    "만약 샘플마다 클래스 별 타깃 확률을 가지고 있다면 catergorical_crossentropy 손실을 사영해야한다.<br>\n",
    "이진 분류나 다중 레이블 이진 분류를 수행한다면 출력층에 \"softmax\"대신 \"sigmoid\"를 사용하고 \"binary_crossentropy\"손실을 사용한다.\n",
    "\n",
    "옵티마이저에 \"sgd\"를 지정하면 기본 확률적 경사하강법을 사용해서 모델을 훈련한다는 의미이다. 즉, 역전파 알고리즘을 수행하는 것이다.\n",
    "\n",
    "마지막으로 분류기 이므로 훈련과 평가시에 정확도를 측정하기 위해서 \"accuracy\"로 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517337fe",
   "metadata": {},
   "source": [
    "### 모델훈련과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcd2852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7261 - accuracy: 0.7597 - val_loss: 0.5212 - val_accuracy: 0.8224\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4909 - accuracy: 0.8296 - val_loss: 0.5058 - val_accuracy: 0.8264\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4438 - accuracy: 0.8458 - val_loss: 0.4042 - val_accuracy: 0.8634\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4146 - accuracy: 0.8540 - val_loss: 0.4318 - val_accuracy: 0.8472\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3942 - accuracy: 0.8626 - val_loss: 0.3879 - val_accuracy: 0.8638\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3781 - accuracy: 0.8663 - val_loss: 0.3760 - val_accuracy: 0.8674\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3630 - accuracy: 0.8706 - val_loss: 0.3616 - val_accuracy: 0.8704\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3518 - accuracy: 0.8752 - val_loss: 0.3578 - val_accuracy: 0.8752\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3416 - accuracy: 0.8792 - val_loss: 0.3407 - val_accuracy: 0.8792\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3312 - accuracy: 0.8819 - val_loss: 0.3378 - val_accuracy: 0.8802\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3232 - accuracy: 0.8848 - val_loss: 0.3629 - val_accuracy: 0.8724\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3155 - accuracy: 0.8870 - val_loss: 0.3497 - val_accuracy: 0.8736\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3072 - accuracy: 0.8891 - val_loss: 0.3305 - val_accuracy: 0.8782\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2999 - accuracy: 0.8931 - val_loss: 0.3315 - val_accuracy: 0.8832\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2943 - accuracy: 0.8938 - val_loss: 0.3225 - val_accuracy: 0.8876\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2894 - accuracy: 0.8958 - val_loss: 0.3142 - val_accuracy: 0.8892\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2829 - accuracy: 0.8978 - val_loss: 0.3385 - val_accuracy: 0.8780\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2773 - accuracy: 0.8985 - val_loss: 0.3052 - val_accuracy: 0.8940\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2723 - accuracy: 0.9034 - val_loss: 0.3020 - val_accuracy: 0.8930\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2666 - accuracy: 0.9053 - val_loss: 0.3062 - val_accuracy: 0.8886\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2619 - accuracy: 0.9053 - val_loss: 0.3374 - val_accuracy: 0.8778\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2577 - accuracy: 0.9077 - val_loss: 0.3004 - val_accuracy: 0.8918\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2532 - accuracy: 0.9086 - val_loss: 0.3051 - val_accuracy: 0.8906\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2479 - accuracy: 0.9103 - val_loss: 0.3014 - val_accuracy: 0.8896\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2439 - accuracy: 0.9122 - val_loss: 0.3044 - val_accuracy: 0.8906\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2407 - accuracy: 0.9134 - val_loss: 0.2978 - val_accuracy: 0.8916\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2355 - accuracy: 0.9151 - val_loss: 0.2959 - val_accuracy: 0.8960\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2320 - accuracy: 0.9170 - val_loss: 0.3146 - val_accuracy: 0.8846\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2278 - accuracy: 0.9172 - val_loss: 0.3024 - val_accuracy: 0.8876\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2244 - accuracy: 0.9191 - val_loss: 0.2996 - val_accuracy: 0.8910\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ebed1",
   "metadata": {},
   "source": [
    "<b>특정 클래스가 조금 등장하는 비대칭적 데이터의 경우에는 fit()메소드를 호출할 때 class_weight 매개변수를 지정하는 것이 좋다. 샘플별로 가중치를 부여하고 싶다면 sample_weight 매개변수를 지정하면 된다. (두값이 모두 지정되면 곱해서 사용한다.)<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5967d28",
   "metadata": {},
   "source": [
    "### 모델을 다시 fit하면 이어서 fit 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47c3a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2203 - accuracy: 0.9203 - val_loss: 0.3215 - val_accuracy: 0.8858\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2165 - accuracy: 0.9229 - val_loss: 0.2899 - val_accuracy: 0.8974\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2133 - accuracy: 0.9243 - val_loss: 0.2883 - val_accuracy: 0.8970\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2103 - accuracy: 0.9250 - val_loss: 0.2928 - val_accuracy: 0.8978\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2063 - accuracy: 0.9267 - val_loss: 0.2921 - val_accuracy: 0.8964\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2039 - accuracy: 0.9271 - val_loss: 0.2951 - val_accuracy: 0.8962\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2006 - accuracy: 0.9282 - val_loss: 0.2938 - val_accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1968 - accuracy: 0.9309 - val_loss: 0.2979 - val_accuracy: 0.8964\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1935 - accuracy: 0.9311 - val_loss: 0.3152 - val_accuracy: 0.8918\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1905 - accuracy: 0.9317 - val_loss: 0.2975 - val_accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b92d70d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f6361",
   "metadata": {},
   "source": [
    "### fit() 메소드가 반환하는 History 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "038836e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True) # 격자 생성\n",
    "plt.gca().set_ylim(0,1) # 수직축의 범위를 0~1로 지정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a21d9",
   "metadata": {},
   "source": [
    "모델의 성능이 너무 낮다면 일반적으로\n",
    "1. 학습률\n",
    "2. 다른 옵티마이저\n",
    "3. 층개수, 뉴런개수, 은닉층의 활성화함수\n",
    "4. 배치크기 \n",
    "순으로 하이퍼라미터를 수정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce263c",
   "metadata": {},
   "source": [
    "### evaluate() 메소드\n",
    "테스트세트로 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "422af5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3312 - accuracy: 0.8864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3311586081981659, 0.8863999843597412]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20f63d",
   "metadata": {},
   "source": [
    "~~엥... 예측 성능이 너무 낮다..~~\n",
    "\n",
    "~~이거를 검색해 봤는데 그냥 진행바에 오류가 있다고 하는데.. 맞는지 모르겠다.~~\n",
    "~~- https://stackoverflow.com/questions/44384924/model-evaluate-in-keras-do-not-cover-all-datapoints~~\n",
    "\n",
    "\n",
    "~~이거는 뉴런들이 dropout 된다는데.. 잘모르겠다~~\n",
    "~~- https://github.com/keras-team/keras/issues/6977~~\n",
    "\n",
    "다시 실행하니까 된다. 이런;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113c429",
   "metadata": {},
   "source": [
    "### 모델을 사용해서 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fcaf763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e387406",
   "metadata": {},
   "source": [
    "### predict_classes 메소드\n",
    "2.6.0 버전이후로 이 메소드가 없어졌다. 그냥 predict메소드에 np.argmax를 적용해서 사용하면 된다"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5edfbff0",
   "metadata": {},
   "source": [
    "y_pred = model.predict_classes(y_proba)\n",
    "\n",
    "#이렇게 사용하면 됨!\n",
    "y_pred = np.argmax(y_proba,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ade67536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba,axis=-1)\n",
    "y_pred\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c73ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024255d3",
   "metadata": {},
   "source": [
    "### 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론(MLP) 만들기\n",
    "캘리포니아 주택가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e3daf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_vaild = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d94e2",
   "metadata": {},
   "source": [
    "<b>분류와 회귀의 차이점은 출력층이 활성화 함수가 없는 하나의 뉴런을 가진다는 것과 손실함수로 평균 제곱 오차를 사용한다는 것이다. <br> 이 데이터는 오차가 많기 때문에 뉴런이 적은 하나의 은닉층을 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c38d980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.1597 - val_loss: 153848.2812\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8361 - val_loss: 19253.9766\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4630 - val_loss: 72827.2031\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4421 - val_loss: 40321.3750\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4318 - val_loss: 60312.2773\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4236 - val_loss: 55164.6133\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 74109.3438\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 82298.5000\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 50631.8281\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 90424.9531\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 114505.2031\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 85884.6406\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 87759.2578\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 71347.3359\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 77832.7734\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 106340.4062\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 97173.3438\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 54409.1367\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 62635.2422\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 45284.5117\n",
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dbe493",
   "metadata": {},
   "source": [
    "### 함수형 API를 사용해 복잡한 모델 만들기\n",
    "Sequential 모델은 쉽지만 입력과 출력이 여러 개거나 더 복잡한 네트워크 토폴로지를 갖는 신경망을 만들어야할 때가 있다.\n",
    "\n",
    "이럴때는 <b>함수형 API</b>를 사용한다. "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0db4e3e2",
   "metadata": {},
   "source": [
    "- <b> 와이드&딥 신경망\n",
    "    ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e325288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input 객체 만들기. 이 객체는 shape와 dtype을 포함해서 모델의 입력을 정의한다. 한 모델은 여러 입력을 가질수 있다.\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "\n",
    "# 30개의 뉴런을 가지고 활성화함수로는 ReLU를 가진 Dense층을 만든다. 이 층은 만들어지자마자 입력과 함께 함수처럼 호출된다.\n",
    "# 케라스에 층이 연결될 방법을 알려주었을 뿐 아직 어떤 데이터도 처리하지 않았다.\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "\n",
    "# 두번째 은닉층을 만든다. 이 층은 hidden1과 연결되어있다.\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "# Concatenate 층을 만들고 또 다시 함수처럼 호출하여 두 번째 은닉층의 출려과 입력을 연결한다. \n",
    "# 아래 함수는 Concatenate 층을 만들고 주어진 입력으로 바로 호출한다.\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "\n",
    "# 하나의 뉴런과 활성화 함수가 없는 출력층을 만들고 Concatenate 층이 만든 결과를 사용해 호출한다.\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "# 마지막으로 사용할 입력과 출력을 지정하여 케라스 Model을 만든다.\n",
    "model_wide_deep = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e68c9f",
   "metadata": {},
   "source": [
    "- <b> 일부 특성은 짧은 경로로 전달하고 다른 특성들은 깊은 경로로 전달하고 싶다면 어떻게 해야할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0fa1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep input\")\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model_two_input_wide_deep = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f67dedea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 2.0458 - val_loss: 23159.0430\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.8263 - val_loss: 170099.2656\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7071 - val_loss: 177741.2500\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6534 - val_loss: 158759.6562\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6161 - val_loss: 129512.7031\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5891 - val_loss: 102645.5859\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5692 - val_loss: 84712.2578\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5541 - val_loss: 71169.1250\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5433 - val_loss: 61333.6250\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5341 - val_loss: 51051.4102\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5264 - val_loss: 43885.4961\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5211 - val_loss: 37952.3008\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5152 - val_loss: 35440.3711\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5105 - val_loss: 33540.6484\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5063 - val_loss: 33860.8906\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5015 - val_loss: 30071.1270\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4985 - val_loss: 30564.4844\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4949 - val_loss: 26689.8301\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4920 - val_loss: 25729.8184\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4886 - val_loss: 28221.2051\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4559\n",
      "1/1 [==============================] - 0s 333ms/step\n"
     ]
    }
   ],
   "source": [
    "model_two_input_wide_deep.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "# 피처가 중복되도 괜찮다.\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model_two_input_wide_deep.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                   validation_data= ((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model_two_input_wide_deep.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model_two_input_wide_deep.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a842cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 30)           210         ['deep input[0][0]']             \n",
      "                                                                                                  \n",
      " wide input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 30)           930         ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 35)           0           ['wide input[0][0]',             \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            36          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_two_input_wide_deep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc6694",
   "metadata": {},
   "source": [
    "- <b> 여러개의 출력이 필요한 경우</b>\n",
    "\n",
    "    ex) \n",
    "    1. 그림에 있는 주요 물체를 분류하고 위치를 알아야 하는 경우. (회귀작업 + 분류작업)\n",
    "    2. 동일한 데이터에서 독립적인 여러 작업을 수행할 때. (다중 작업 분류)\n",
    "    3. 규제기법을 사용하는 경우. 하위 네트워크가 나머지 네트워크에 의존하지 않고 그 자체로 유용한지를 판단할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "729ab40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 6ms/step - loss: 0.9897 - main_output_loss: 0.8777 - aux_output_loss: 1.9980 - val_loss: 52730.6016 - val_main_output_loss: 30485.6211 - val_aux_output_loss: 252935.3125\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6853 - main_output_loss: 0.6422 - aux_output_loss: 1.0726 - val_loss: 23022.1328 - val_main_output_loss: 9170.2549 - val_aux_output_loss: 147688.9531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5837 - main_output_loss: 0.5465 - aux_output_loss: 0.9181 - val_loss: 27494.3398 - val_main_output_loss: 20054.1270 - val_aux_output_loss: 94456.1719\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5384 - main_output_loss: 0.5087 - aux_output_loss: 0.8053 - val_loss: 23686.7637 - val_main_output_loss: 15905.2549 - val_aux_output_loss: 93720.3750\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5134 - main_output_loss: 0.4858 - aux_output_loss: 0.7615 - val_loss: 16632.1035 - val_main_output_loss: 11024.4229 - val_aux_output_loss: 67101.2422\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5049 - main_output_loss: 0.4810 - aux_output_loss: 0.7207 - val_loss: 15756.3145 - val_main_output_loss: 10467.4854 - val_aux_output_loss: 63355.7617\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4881 - main_output_loss: 0.4655 - aux_output_loss: 0.6916 - val_loss: 19588.2949 - val_main_output_loss: 15488.7764 - val_aux_output_loss: 56484.0430\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4720 - main_output_loss: 0.4504 - aux_output_loss: 0.6658 - val_loss: 12317.5771 - val_main_output_loss: 8832.5439 - val_aux_output_loss: 43682.8555\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4659 - main_output_loss: 0.4456 - aux_output_loss: 0.6493 - val_loss: 15805.2969 - val_main_output_loss: 12942.4873 - val_aux_output_loss: 41570.5703\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4603 - main_output_loss: 0.4411 - aux_output_loss: 0.6338 - val_loss: 26992.6816 - val_main_output_loss: 24485.9531 - val_aux_output_loss: 49553.2578\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4501 - main_output_loss: 0.4316 - aux_output_loss: 0.6170 - val_loss: 16321.3477 - val_main_output_loss: 13626.0508 - val_aux_output_loss: 40579.0156\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4410 - main_output_loss: 0.4224 - aux_output_loss: 0.6081 - val_loss: 17021.5996 - val_main_output_loss: 14281.3223 - val_aux_output_loss: 41684.0898\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4401 - main_output_loss: 0.4225 - aux_output_loss: 0.5984 - val_loss: 10177.6523 - val_main_output_loss: 8202.1025 - val_aux_output_loss: 27957.6035\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4303 - main_output_loss: 0.4136 - aux_output_loss: 0.5808 - val_loss: 11164.1865 - val_main_output_loss: 9658.3018 - val_aux_output_loss: 24717.1680\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4223 - main_output_loss: 0.4057 - aux_output_loss: 0.5718 - val_loss: 6461.2476 - val_main_output_loss: 4706.1230 - val_aux_output_loss: 22257.3750\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4399 - main_output_loss: 0.4226 - aux_output_loss: 0.5952 - val_loss: 8465.5381 - val_main_output_loss: 7001.2178 - val_aux_output_loss: 21644.4043\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4357 - main_output_loss: 0.4185 - aux_output_loss: 0.5903 - val_loss: 6951.1729 - val_main_output_loss: 4779.8081 - val_aux_output_loss: 26493.4609\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4217 - main_output_loss: 0.4069 - aux_output_loss: 0.5548 - val_loss: 14196.0215 - val_main_output_loss: 13819.5918 - val_aux_output_loss: 17583.8672\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4109 - main_output_loss: 0.3958 - aux_output_loss: 0.5472 - val_loss: 7080.9155 - val_main_output_loss: 6503.6650 - val_aux_output_loss: 12276.1924\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4056 - main_output_loss: 0.3909 - aux_output_loss: 0.5373 - val_loss: 9726.9980 - val_main_output_loss: 8696.7588 - val_aux_output_loss: 18999.1465\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3628 - main_output_loss: 0.3488 - aux_output_loss: 0.4885\n",
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep input\")\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "main_output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "\n",
    "model_two_output_wide_deep = keras.Model(inputs=[input_A, input_B], outputs=[main_output, aux_output])\n",
    "\n",
    "model_two_output_wide_deep.compile(loss=[\"mse\", \"mse\"], optimizer=\"sgd\", loss_weights = [0.9, 0.1])\n",
    "\n",
    "# 피처가 중복되도 괜찮다.\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model_two_output_wide_deep.fit((X_train_A, X_train_B), [y_train,y_train], epochs=20,\n",
    "                   validation_data= ((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "\n",
    "mse_test = model_two_output_wide_deep.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred_main, y_pred_aux = model_two_output_wide_deep.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1cc387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.3628 - main_output_loss: 0.3488 - aux_output_loss: 0.4885\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss ,aux_loss = model_two_output_wide_deep.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "273b6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dynamic_WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # 표준 매개변수를 처리한다. ex) name\n",
    "        self.hidden1 = keras.layers.Dense(units, activation= activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation= activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A , input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input1, input2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "dynamic_wide_deep_model = Dynamic_WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8bbeb",
   "metadata": {},
   "source": [
    "이 예제는 함수형 API와 굉장히 비슷하지만, call함수에 무수히 많은 계산들을 넣을 수도 있다. 자유자재로 변형이 가능하다는 것이다.\n",
    "\n",
    "하지만 call함수에 층간의 관계가 있으므로 모델을 저장하거나 복사할 수가 없다는 불편함이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0e04d",
   "metadata": {},
   "source": [
    "### 모델 저장과 복원\n",
    "시퀀셜 API나 함수형 API를 사용하면 모델을 저장하는 것은 다음과 같이 매수 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20475089",
   "metadata": {},
   "source": [
    "``` python\n",
    "## 모델 저장\n",
    "model = keras.models.Sequential([...])\n",
    "model.compile([...])\n",
    "model.fit([...])\n",
    "model.save(\"my_keras_model.h5\")\n",
    "\n",
    "## 모델 불러오기\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbf7ee",
   "metadata": {},
   "source": [
    "## 콜백 사용하기\n",
    "fit 메소드에서 체크포인트를 저장하는 방법"
   ]
  },
  {
   "cell_type": "raw",
   "id": "774cf933",
   "metadata": {},
   "source": [
    "# 간단한 체크포인트 저장\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckPoint(\"my_keras_model.h5\")\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22a01cfa",
   "metadata": {},
   "source": [
    "# 최상의 모델만 저장하는 callbacks 메소드 사용법\n",
    "# 조기종료를 구현하는 것임\n",
    "checkpoint_cb = keras.callbacks.ModelCheckPoint(\"my_keras_model.h5\",\n",
    "                                               save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n",
    "\n",
    "model = keras.model.load_model(\"my_keras_model.h5\") # 최상의 모델로 복원"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55ff7c7b",
   "metadata": {},
   "source": [
    "# 조기종료를 구현하는 방법\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weight=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ad312",
   "metadata": {},
   "source": [
    "### 텐서보드를 사용해서 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb5aa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23f9ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3637 - val_loss: 53801.4961\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 27846.7598\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 34074.1211\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 28352.1562\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 40420.8750\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3562 - val_loss: 44642.9961\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3522 - val_loss: 70705.3125\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 51822.0352\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3488 - val_loss: 27289.7949\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 28899.6191\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 59179.4453\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 62973.7539\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3432 - val_loss: 44809.3203\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 58504.3828\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3398 - val_loss: 52159.1680\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3387 - val_loss: 51194.6133\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3410 - val_loss: 42015.3672\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 60589.4570\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 52889.5703\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 39743.0469\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 44446.1836\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3340 - val_loss: 38647.7695\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 68149.8516\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 37388.0586\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 33523.4414\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3321 - val_loss: 89337.3906\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 39693.6562\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 87049.3125\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 32333.0742\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3298 - val_loss: 42891.7383\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e681f6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17440), started 3 days, 23:07:48 ago. (Use '!kill 17440' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-35a7223be45a6497\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-35a7223be45a6497\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 주피터 노트북 내부에서 텐서보드 사용\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331c47bf",
   "metadata": {},
   "source": [
    "### 신경망 하이퍼파라미터 튜닝하기\n",
    "그리드서치 or RandomizedSearchCV를 사용하기 위해서는 케라스 모델을 사이킷런 추정기처럼 보이도록 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf694199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_12716/3126652774.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(bulid_model)\n"
     ]
    }
   ],
   "source": [
    "def bulid_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayers(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(bulid_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cd2ac",
   "metadata": {},
   "source": [
    "위와 같은 오류가 떴다. 그래서 scikeras를 설치했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e589cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d65f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "def bulid_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "keras_reg = scikeras.wrappers.KerasRegressor(bulid_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f5abb",
   "metadata": {},
   "source": [
    "사이킷런 추정기처럼 보이게 하는 래퍼를 감싸면 사이킷런에서 사용되는 메소드를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1a68f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.5383 - val_loss: 100063.3438\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7809 - val_loss: 113323.7109\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6223 - val_loss: 63210.6211\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5673 - val_loss: 89869.0156\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5348 - val_loss: 61910.8594\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5124 - val_loss: 44106.4922\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 38721.6602\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4917 - val_loss: 29073.8086\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4848 - val_loss: 28429.7500\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4784 - val_loss: 24399.7676\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4728 - val_loss: 30772.4336\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4688 - val_loss: 20830.1094\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4646 - val_loss: 28682.2227\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4612 - val_loss: 23858.8535\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4574 - val_loss: 21225.7070\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4558 - val_loss: 17352.3867\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4544 - val_loss: 13942.7734\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4496 - val_loss: 16115.6895\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4468 - val_loss: 16365.9072\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4448 - val_loss: 14620.6572\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4423 - val_loss: 15221.4053\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4402 - val_loss: 17524.0215\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4383 - val_loss: 20436.1406\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4362 - val_loss: 17211.5273\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4347 - val_loss: 16623.7402\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 16188.7119\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4312 - val_loss: 20095.2461\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4286 - val_loss: 18477.9551\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4273 - val_loss: 19401.5156\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4255 - val_loss: 22061.9883\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4234 - val_loss: 20381.5820\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4226 - val_loss: 16292.7051\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4222 - val_loss: 26374.3711\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4199 - val_loss: 22145.8359\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4194 - val_loss: 26523.0312\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 22153.1582\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4157 - val_loss: 21012.2773\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 22638.6680\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4218 - val_loss: 20419.2969\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4253 - val_loss: 18137.0430\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 25617.5898\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 24393.5430\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 13207.9521\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 22657.6992\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 16383.0879\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 19242.6172\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 21285.4648\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 22623.3398\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 17931.7148\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3968 - val_loss: 18836.7363\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020B924A7AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "162/162 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=50,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd981437",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter learning_rate for estimator KerasRegressor.\nThis issue can likely be resolved by setting this parameter in the KerasRegressor constructor:\n`KerasRegressor(learning_rate=0.007128700290480555)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12716/2901470443.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[0;32m     14\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1754\u001b[0m             ParameterSampler(\n\u001b[0;32m   1755\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    820\u001b[0m                     )\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m   1166\u001b[0m                     \u001b[1;31m# Give a SciKeras specific user message to aid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m                     \u001b[1;31m# in moving from the Keras wrappers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m   1169\u001b[0m                         \u001b[1;34mf\"Invalid parameter {param} for estimator {self.__name__}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m                         \u001b[1;34m\"\\nThis issue can likely be resolved by setting this parameter\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter learning_rate for estimator KerasRegressor.\nThis issue can likely be resolved by setting this parameter in the KerasRegressor constructor:\n`KerasRegressor(learning_rate=0.007128700290480555)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "keras_reg.get_params().keys()\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\": np.arange(1,100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb14f94",
   "metadata": {},
   "source": [
    "으악 책에 나온대로 안하고 sci-keras를 사용하니까 오류가 뜸... 아래는 제대로 나온다ㅜㅜ 뭔지를 모르겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18981af4",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d53a9a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp/ipykernel_12716/3730239423.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3404cef3",
   "metadata": {},
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_distribs = {\n",
    "    'n_hidden': [2,3,4,5],\n",
    "    'n_neurons': np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c74dc3f",
   "metadata": {},
   "source": [
    "# 이렇게 하면 최적 파라미터가 나온다. 그런데 너너너너너너무무무무 학습을 오래해서 그냥 이걸로 대체함.\n",
    "rnd_search_cv.best_parmas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c5949",
   "metadata": {},
   "source": [
    "잘 모르겠는 부분이 있는데, 래퍼로 감싸면 scikit_learn형태일텐데 keras의 파라미터를 받아서 랜덤서치를 해도 되는건가??? \n",
    "scikeras를 사용했을 때는 오류가 떠서 의문이 들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77328bee",
   "metadata": {},
   "source": [
    "### 연습문제 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af0895",
   "metadata": {},
   "source": [
    "논리 연산에 대한 문제는 잘 모르겠다..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277a7bb",
   "metadata": {},
   "source": [
    "### 연습문제 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b588f",
   "metadata": {},
   "source": [
    "고전적인 퍼셉트론보다 로지스틱 회귀 분류가 선호되는 이유는 \n",
    "1. 클래스별 확률을 제공하지 않음 (왜냐하면 계단형식의 활성화함수를 사용하기 때문이다.)\n",
    "2. 데이터가 선형적으로 구분 될 때만 수렴한다. (논리연산과 관련이 있는 것 같은데 잘 모르겠다.)\n",
    "이를 해소하기 위해서는 활성화 함수를 로지스틱 활성화 함수로 바꾸고 경사하강법으로 훈련한다. 또한 다층 퍼셉트론을 사용하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe5a7f",
   "metadata": {},
   "source": [
    "### 연습문제 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae6992",
   "metadata": {},
   "source": [
    "경사가 없는 계단 함수는 경사하강법을 적용할 수 없기 때문에 경사가 있는 로지스틱 활성화 함수를 사용했다. \n",
    "또한, 실제 뉴런의 활성화함수 모양이 로지스틱 활성화 함수와 비슷하다고 생각했기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df4b35",
   "metadata": {},
   "source": [
    "### 연습문제 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadcfd77",
   "metadata": {},
   "source": [
    "1. ReLU\n",
    "2. tanh 함수\n",
    "3. 시그모이드 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bca4d",
   "metadata": {},
   "source": [
    "### 연습문제 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cdbc20",
   "metadata": {},
   "source": [
    "- 입력 행렬 X의 크기는 m * 10 이다. (m은 배치의 크기이다.)\n",
    "- 은닉층의 가중치 행렬(W_h)은 10 * 50 이다. 은닉층의 편향(b_h)행렬은 1 * 50 이다.\n",
    "- 출력층의 가중치 행렬(W_o)은 50 * 3 이다. 은닉층의 편향(b_o)행렬은 1 * 3 이다. \n",
    "- 네트워크 출력 행렬 Y의 크기는 m * 3이다. \n",
    "\n",
    "\n",
    "- 출력 행렬: Y = ReLU(ReLU(W_h\\*X+b_h)\\*W_o+b_o)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6971e1a",
   "metadata": {},
   "source": [
    "### 연습문제 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb9888",
   "metadata": {},
   "source": [
    "~~스팸 구별문제는 출력층에 스팸/비스팸을 구별할 수 있도록 두개의 뉴런이 필요하다. 출력층 함수는 출력 결과가 서로 배타적이므로 소프트맥스함수가 적절할 것 같다.~~ 이 방법이 아닌 한개의 출력 뉴런을 가지고 활성화함수는 로지스틱 활성화 함수를 가지는 뉴런이여도 괜찮다.\n",
    "보통 이진 분류에는 로지스틱 활성화 함수가 사용된다. \n",
    "\n",
    "\n",
    "Mnist 구별문제는 출력층에 10개의 뉴런이 필요하다. 또한 소프트 맥스함수를 사용하면 될 것 같다.\n",
    "\n",
    "회귀문제는 출력에 1개의 뉴런이 필요하다. 이건 활성화 함수가 필요 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724d700",
   "metadata": {},
   "source": [
    "### 연습문제 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68fc8fc",
   "metadata": {},
   "source": [
    "역전파는 여러 층으로 이루어져 있는 모델의 뉴런들을 학습하는 방법이다. 여기에는 경사하강법이 이용되는데 이때 그래디언트를 계산하기 위한 방법이 후진 모드 자동 미분이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf014bd",
   "metadata": {},
   "source": [
    "### 연습문제 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ffd22",
   "metadata": {},
   "source": [
    "다층 퍼셉트론에서 조정할 수 있는 파라미터는\n",
    "- 뉴런 개수\n",
    "- 은닉층 수\n",
    "- 학습률\n",
    "- 옵티마이저\n",
    "- 활성화 함수\n",
    "가 있다. \n",
    "과대 적합이 발생하면 뉴런개수를 줄이고, 은닉층 수를 줄이는 방법이 있고, \n",
    "규제를 통해서 과대적합을 해소할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5a50a",
   "metadata": {},
   "source": [
    "### 연습문제 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e3161",
   "metadata": {},
   "source": [
    "#### 0. 모듈 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab35a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76d0a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session\n",
    "# keras.backend.clear_session()\n",
    "# 현재 TF 그래프를 없애고, 새로운 TF 그래프를 만듭니다.\n",
    "#오래된 모델 혹은 층과의 혼란을 피할 때 유용합니다.\n",
    "keras.backend.clear_session()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61555857",
   "metadata": {},
   "source": [
    "#### 1. 데이터 적재/ test_train셋 분리/ 스케일링/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02d4c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "mnist_data = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50e573b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기:  (55000, 28, 28)\n",
      "X_valid 크기:  (5000, 28, 28)\n",
      "y_train 크기:  (55000,)\n",
      "y_valid 크기:  (5000,)\n"
     ]
    }
   ],
   "source": [
    "train, test= mnist_data\n",
    "X_train_full, y_train_full, X_test, y_test = train[0], train[1], test[0], test[1]\n",
    "\n",
    "# 검증셋을 20%로 하니까 accuracy가 너무 낮았다. 그래서 작게했다. \n",
    "X_train, X_valid = X_train_full[5000:], X_train_full[:5000]\n",
    "y_train, y_valid = y_train_full[5000:], y_train_full[:5000]\n",
    "\n",
    "# mnist 데이터는 0~255의 범위를 가지므로 0~1 사이의 범위를 갖도록 \n",
    "X_train, X_valid, X_test = X_train/255.0, X_valid/255.0, X_test/255.0\n",
    "\n",
    "\n",
    "print(\"X_train 크기: \", X_train.shape)\n",
    "print(\"X_valid 크기: \", X_valid.shape)\n",
    "print(\"y_train 크기: \", y_train.shape)\n",
    "print(\"y_valid 크기: \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a5273",
   "metadata": {},
   "source": [
    "#### 2. 모델 구현2. 모델 구현<br>\n",
    "- 시퀀셜 api 사용 \n",
    "\n",
    "A. 입력층에 784개의 뉴런이 필요함<br>\n",
    "B. 첫번째 은닉층에 300개의 뉴런 (활성화 함수 ReLU)<br>\n",
    "C. 두번째 은닉층에 100개의 뉴런 (활성화 함수 ReLU)<br>\n",
    "D. 출력층에 10개의 뉴런을 사용한다. (활성화 함수 softmax)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40301245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_my = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6959a",
   "metadata": {},
   "source": [
    "#### 3. 모델 compile<br>\n",
    "\n",
    "A. 학습률 (학습률을 지수적으로 증가시키면서 찾기)<br>\n",
    "B. 옵티마이저   <br>\n",
    "C. 손실함수 (분류기 때문에 카테고리 엔트로피 함수 사용하면 될 듯)<br>\n",
    "D. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4109b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_my.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87dde8b",
   "metadata": {},
   "source": [
    "#### 4. 모델 fit <br>\n",
    "A. X_train, y_train<br>\n",
    "B. 조기종료 (X_valid, y_valid)<br>\n",
    "C. 텐서 보드 사용하기<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5356dea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6301 - accuracy: 0.8345 - val_loss: 0.3080 - val_accuracy: 0.9166\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2878 - accuracy: 0.9184 - val_loss: 0.2388 - val_accuracy: 0.9330\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2329 - accuracy: 0.9336 - val_loss: 0.1979 - val_accuracy: 0.9444\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1971 - accuracy: 0.9440 - val_loss: 0.1739 - val_accuracy: 0.9546\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.1716 - accuracy: 0.9509 - val_loss: 0.1543 - val_accuracy: 0.9584\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1520 - accuracy: 0.9570 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1363 - accuracy: 0.9623 - val_loss: 0.1304 - val_accuracy: 0.9642\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1235 - accuracy: 0.9645 - val_loss: 0.1261 - val_accuracy: 0.9666\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1128 - accuracy: 0.9683 - val_loss: 0.1151 - val_accuracy: 0.9690\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.1041 - accuracy: 0.9706 - val_loss: 0.1065 - val_accuracy: 0.9710\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0958 - accuracy: 0.9733 - val_loss: 0.1047 - val_accuracy: 0.9722\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0887 - accuracy: 0.9751 - val_loss: 0.1004 - val_accuracy: 0.9712\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0825 - accuracy: 0.9767 - val_loss: 0.0937 - val_accuracy: 0.9742\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0768 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9742\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0717 - accuracy: 0.9802 - val_loss: 0.0878 - val_accuracy: 0.9760\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0671 - accuracy: 0.9808 - val_loss: 0.0863 - val_accuracy: 0.9772\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0628 - accuracy: 0.9826 - val_loss: 0.0858 - val_accuracy: 0.9762\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0592 - accuracy: 0.9838 - val_loss: 0.0823 - val_accuracy: 0.9770\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0555 - accuracy: 0.9849 - val_loss: 0.0809 - val_accuracy: 0.9768\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0523 - accuracy: 0.9853 - val_loss: 0.0805 - val_accuracy: 0.9764\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0494 - accuracy: 0.9867 - val_loss: 0.0769 - val_accuracy: 0.9790\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0465 - accuracy: 0.9871 - val_loss: 0.0765 - val_accuracy: 0.9800\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.0796 - val_accuracy: 0.9766\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0411 - accuracy: 0.9895 - val_loss: 0.0758 - val_accuracy: 0.9788\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0392 - accuracy: 0.9899 - val_loss: 0.0737 - val_accuracy: 0.9796\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0368 - accuracy: 0.9904 - val_loss: 0.0715 - val_accuracy: 0.9798\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.0712 - val_accuracy: 0.9810\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0329 - accuracy: 0.9919 - val_loss: 0.0739 - val_accuracy: 0.9798\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.0730 - val_accuracy: 0.9796\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0292 - accuracy: 0.9931 - val_loss: 0.0714 - val_accuracy: 0.9804\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.0719 - val_accuracy: 0.9800\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 0.0710 - val_accuracy: 0.9810\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 0.0717 - val_accuracy: 0.9800\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0729 - val_accuracy: 0.9802\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0222 - accuracy: 0.9955 - val_loss: 0.0706 - val_accuracy: 0.9814\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 0.0730 - val_accuracy: 0.9800\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0198 - accuracy: 0.9964 - val_loss: 0.0685 - val_accuracy: 0.9816\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0188 - accuracy: 0.9967 - val_loss: 0.0706 - val_accuracy: 0.9810\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0179 - accuracy: 0.9971 - val_loss: 0.0707 - val_accuracy: 0.9812\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0169 - accuracy: 0.9973 - val_loss: 0.0720 - val_accuracy: 0.9814\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.0700 - val_accuracy: 0.9820\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.0698 - val_accuracy: 0.9816\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0145 - accuracy: 0.9980 - val_loss: 0.0739 - val_accuracy: 0.9790\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0138 - accuracy: 0.9982 - val_loss: 0.0701 - val_accuracy: 0.9812\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0130 - accuracy: 0.9985 - val_loss: 0.0712 - val_accuracy: 0.9808\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0126 - accuracy: 0.9985 - val_loss: 0.0710 - val_accuracy: 0.9818\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.0709 - val_accuracy: 0.9820\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0112 - accuracy: 0.9987 - val_loss: 0.0732 - val_accuracy: 0.9810\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.0708 - val_accuracy: 0.9828\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.0722 - val_accuracy: 0.9812\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 0.0721 - val_accuracy: 0.9824\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0714 - val_accuracy: 0.9826\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0724 - val_accuracy: 0.9814\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0726 - val_accuracy: 0.9818\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.0742 - val_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0079 - accuracy: 0.9995 - val_loss: 0.0752 - val_accuracy: 0.9816\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0727 - val_accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "\n",
    "history = model_my.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks= [early_stopping_cb, tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78c6943a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17440), started 3 days, 23:19:41 ago. (Use '!kill 17440' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c54069a371a5060c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c54069a371a5060c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86e6f0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0713987722992897, 0.9794999957084656]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_my.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbc9e8",
   "metadata": {},
   "source": [
    "### 학습률 튜닝 \n",
    "이 아래 코드는 잘 모르겠어서 답안을 참조했습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33b94a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘은 모르겠지만 이해한 내용을 써본다.\n",
    "# keras 는 low-level에서의 조정은 안된다. 왜냐하면 쉽게 사용하기 위한 딥러닝 api이기 때문이다. \n",
    "# 하지만 keras.backend를 사용하면 low-level에서의 조정이 가능하다.\n",
    "## set_value\n",
    "## keras.backend.set_value(x, value) 로 사용한다. \n",
    "#  반복마다 학습률을 증가시키기 위해 콜백을 사용합니다. 이 콜백은 반복마다 학습률과 손실을 기록합니다.\n",
    "K = keras.backend\n",
    "\n",
    "# 학습률을 지수함수적으로 증가시키면서 성능을 보는 콜백함수를 만들 클래스를 만든 것?\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "        \n",
    "        \n",
    "    # 파라미터로 들어간 batch는 잘 모르겠다. logs 는 모델이 학습된 기록들을 가져오는 것 같다.\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        # 현재 학습 모델의 학습률을 가져와서 리스트에 추가\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        # 현재 학습 모델의 손실을 리스트에 추가\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        # 학습률에 self.factor을 곱한값을 학습률로 재설정\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46760b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_session\n",
    "# keras.backend.clear_session()\n",
    "# 현재 TF 그래프를 없애고, 새로운 TF 그래프를 만듭니다.\n",
    "#오래된 모델 혹은 층과의 혼란을 피할 때 유용합니다.\n",
    "keras.backend.clear_session()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d57c6b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 11s 6ms/step - loss: nan - accuracy: 0.5754 - val_loss: nan - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "model_anwser = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_anwser.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)\n",
    "\n",
    "history = model_anwser.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b7f0999",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAivklEQVR4nO3deXhV1dn+8e+TmSRACIFAQoAQQECGMIjMBKtWEAHrUMdWRZGqrfa1Wuvr29pq9ddqtSpWxVacWtEqKgqCVQkIgoAIAgYQIUAYBAIEwxBIsn5/5EBjTDAHs3OS7PtzXfvy7OGc87CEfZ+1h7XNOYeIiPhXWKgLEBGR0FIQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIz0WEuoBghcc2db27dQp1GQ3egQMHiIuLC3UZDZ7auebtKDjM7sIiuqc2Pb5M7QyffPLJbudci8rW1bsgiGjakuwFi4iPrnel1yvZ2dlkZWWFuowGT+1c8+5/J4dnF+Sy9N6Rx5epncHMNlW1rl4eGjpQVBzqEkREGox6GQRf7ioMdQkiIg1GvQyCjbsPhLoEEZEGo14eaH92QS7OwfaCQ8RGRTBxeAbhYRbqskRE6qV6GQRf7CzkrjdWHZ9/YPZa+rRNoGXjGAqLiomJDOeCPqkM7pREk5jIEFYqIlL31bsgSE1oRGng9TWD09lVWER+YRHLt+xj2eZ9ZLSIY+f+It7L+QqAQRnNGdqpBWd0aUl6UhxREfXyaJiIiGfqXRAkxkWx+L5RmIHZfw8HOef4an8RrZrGcPhoCbNX7+DfS/NYva2Aj77M50+z1mAGvdokMLpna4Z2akHn5PhvfIaIiB/VuyAACKvkfICZ0appDAAxkeGMzUxlbGYqUHaV0dLcPWzYdYDstbu4d0YOkENSfDRjM1MY2b0Vvds203kGEfGlehkEwcpoEU9Gi3gAfjOqK1v2HGThl/m8l/MVLyzcxD/mbyQpPprT0xM5r1cKwzu3oFFUeIirFhGpHb4IgorSEmNJS4zl4tPSKDh4lA/X7+KdVTtY9GU+M1ZuJyYyjKzOLRnXO4VhnVsQG+XLZhIRn/D9Hq5pbCSje6YwumcKR0tKWbxxD7NX72DWqh3MWr0DM8hMS+CsbsmMy0wlJaFRqEsWEalRvg+C8iLDwxjcMYnBHZP47ehuLPgyn09y95C9bhd/nrWWP89aS9fWTRjZvRUX9G1DqkJBRBoABUEVIsLDGN65BcM7t+B/zj6FzfkHeXvlNuas2cnD763j4ffW0bdtM87qlsyoHq1JS4wNdckiIidFQVBNbZvHckNWR27I6siWPQeZtmwr736+g/vfWcP976yhU8t4zuyWzKWntaVtc4WCiNQfCoKTkJYYy81nduLmMzuxOf8gs1fvIHvdTibP28CTc7+kX7tm/PDUVozs0VqHj0SkzlMQfE9tm8dy3bAOXDesAzsKDjN1yWZmr/6Ke2fkcO+MHPq1a8bF/dIY3au1rj4SkTpJe6Ya1KppDLec2ZlbzuxM7u4DzFi5nWnL8rj9tc+4Z8bnnN87lUv7t6Vr6yahLlVE5DgFgUfaJ8Vx44iO3JCVwZLcvby0eDNTl2zh+YWb6NWmKRf1S+O8Xik0baRB8UQktBQEHjMz+qcn0j89kd+d141py7byytIt3PXGKu55+3POPrUVF/Vtw5COSZUOnSEi4jUFQS1KiI3imiHpXD24Pau27ueVpVuYvmIbb63YRnpSHD/LyuD83qlEhmuEVBGpPdrjhICZ0aNNU+4Z152P7/wBj1ySSWxUOLe/+hlD/zSHh/+zjn0Hj4S6TBHxCfUIQuzYSKljeqWQvXYXzy3M5ZH3v+Af8zfyk4HtGD8knebx0aEuU0QaMAVBHWFmjOjSkhFdWrJmx34mfbCeJ+Z+yZQFuVwxoC3XDetAy8YxoS5TRBogHRqqg7q0asKky/rwn18OZ2T3Vvxj/kaG/mkOd09fzc79h0Ndnkjd5kJdQP2jIKjDOraM56EfZ/LBrVmMzUzhxUWbOPuv83h5yWZKS/W3XaQqevBgcBQE9UD7pDj+fGEvZv9yGBkt4vn1aysZ8/h8PljzFc4pEETk+1EQ1CMZLeJ5deJA/vrjTPYdPMo1zy5l3OMLyF67M9SliUg9piCoZ8yMcb1TmfOrLP50QQ/yDxzhqilLuHrKYjbsKgx1eSJSDykI6qnI8DB+fFpbPrg1i7vO7cqS3L388K/zuP+dHAqLikNdnojUIwqCei4qIoxrh3bgg18NZ1xmKk/N3cCIB7N5a8U2nT8QkWrxLAjMLM3M5phZjpmtNrObK9nGzOxRM1tvZp+ZWR+v6mnoWjaO4YGLevHGjYNp1SSGn7/0Kdc9/wk7CnS5qYicmJc9gmLgVudcV2AAcKOZdauwzUigU2CaADzhYT2+kJmWwOs3DOLOUV348ItdnPXQXF5avFm9AxGpkmdB4Jzb7pxbFnj9NZADpFbYbCzwvCuzCEgws9Ze1eQXEeFhTBiWwexbhnFqahN+M20llz39Mbm7D4S6NBGpg2rlHIGZtQd6Ax9XWJUKbCk3n8e3w0JOUvukOP517QDu/1EPVm0t4JxH5vH0vA2U6GY0ESnH87GGzCweeA24xTm3v+LqSt7yrb2UmU2g7NARycnJZGdn13SZDVpr4A8DI3lu9RH+ODOHVxeuZULPaJo3qvp3QGFhodq5Fqida97mLUcoLSn9RruqnU/M0yAws0jKQuCfzrlplWySB6SVm28DbKu4kXNuMjAZoF+/fi4rK6vmi/WBcT90TFu2ld++uYq7Pz7KPWO7MzYzBavkfvzs7GzUzt5TO9e8hQdzCMvL/Ua7qp1PzMurhgz4B5DjnHuois2mAz8JXD00AChwzm33qia/MzMu6NuGmTcPpXNyY255eTk3/etT9h7Qsw9E/MzLcwSDgSuBM8xseWAaZWYTzWxiYJuZwAZgPfA0cIOH9UhAu+ZxvHL9QG774Sm8+/kOfvjXeczRMBUivuXZoSHn3HwqPwdQfhsH3OhVDVK18DDjxhEdyTqlBb98eTlXT1nC5ae35X/P7UpslB5TIeInurPY505Nacr0m4Zw3dB0/rV4M+c//hEbdZmpiK8oCISYyHD+99xuPHd1f3Z+fZgxj83n050ar0jELxQEctywzi146+dDaJcUyyPLinh8znrdkSziAwoC+YY2zWJ5deIgBrQO54HZa7n1lRUUFZeEuiwR8ZCCQL4lJjKc63tGc+tZnZn26VYuf/pj8guLQl2WiHhEQSCVMjN+/oNOTLqsNyu3FjD28QWs++rrUJclIh5QEMgJje6ZwivXD6SouJQf/e0jPRZTpAFSEMh36pWWwPSbBtM2MZZrnl3ClAUbdRJZpAFREEi1tG7aiH9PHMiZXZP5/Vufc9cbqzhaUhrqskSkBigIpNrioiN48oq+TByewT8/3sxVUxZrnCKRBkBBIEEJCzPuGNmFBy/qxZLcvYx+bD5Lc/eEuiyR43TQMngKAjkpF/Ztw7+vH0hYGFz81EIe+s86SvXAG6kj7MTDnEkFCgI5ab3SEpj5i6Gc37sNj77/BRNeWMrXh4+GuiwRCZKCQL6XxjGRPHhRT34/5lTmrN3F+X/ToHUi9Y2CQL43M+Ong9rzwvj+5BcWMXbSfOau2xXqskSkmhQEUmMGZSQx/aYhpCQ04uopi5k870vdbyBSDygIpEalJcYy7YZBnNO9FffNXMMvX17O4aMatE6kLlMQSI2LjYrg8cv68KuzO/Pmim1c9ORCthccCnVZIlIFBYF4wsy46YxOPH1lPzbuPsB5j81n0Yb8UJclIpVQEIinzuyWzBs3DqJJo0gu//vH/P3DDTpvIFLHKAjEcx1bNubNGwdzVtdk7p2Rw00vfcqBIj0KU6SuUBBIrWgcE8kTV/ThNyO78M7K7Vz45ELy9h4MdVkigoJAapGZcf3wDKZc3Z+8vQc57zHdbyBSFygIpNYN79yC6TcNIblJDFdNWcwj732hcYpEQkhBICGRnhTH6zcM5vzMVB5+bx3XPLeEPRrSWiQkFAQSMo2iwvnLxb24d1x3Plqfz6hHPmTFln2hLkvEdxQEElJmxhUD2jHthkFEhBsXP7WQN5dvDXVZIr6iIJA6oXtqU968cTC92iRw89Tl3PXGSoqKNTSFSG1QEEid0Tw+mn9edzoThnXgxUWbufCJhWzO1yWmIl5TEEidEhkexp2jujL5yr5syj/AuY99yLurd4S6LJEGTUEgddLZp7Zixi+G0r55HBNe+IT7ZuZwtKQ01GWJNEgKAqmz0hJj+ffEgVw5oB2T523g0smL2FFwONRliTQ4CgKp02Iiw7lnXHceuSSTz7fvZ9SjH/J+zlehLkukQVEQSL0wNjP1+N3I459byu/eXKUH3ojUEAWB1BsdW8bzxo2DGD8knecWbmLspAWs3fF1qMsSqfcUBFKvREeE83+ju/Hs1aeRf+AI502az9PzNlCisYokQM+7CJ6CQOqlrFNaMuuWoQzv3II/zszh0smL2JR/INRlSR1QUgoRYRbqMuoVz4LAzJ4xs51mtqqK9VlmVmBmywPTb72qRRqmpPhoJl/Zl79c1Iuc7fsZ+ciHvLhok34R+lxxaSnh4QqCYHjZI3gWOOc7tvnQOZcZmP7gYS3SQJkZF/Rtw+xfDqNP22bc9cYqfvLMYrYXHAp1aRIixaWOiDAd7AiGZ63lnJsH7PHq80XKS0loxPPX9OeesaeyNHcvZz88j2nL8tQ78KGSEqdDQ0EyL/+hmFl74G3nXPdK1mUBrwF5wDbgV8651VV8zgRgAkBycnLfqVOnelSxHFNYWEh8fHyoyzgpXx0o5emVRazfV0rf5HB+2i2aJtF1c8dQn9u5rnr6syLW7CnhL1mxx5epnWHEiBGfOOf6VbYulEHQBCh1zhWa2SjgEedcp+/6zH79+rmlS5fWfLHyDdnZ2WRlZYW6jJNWUur4+4cb+Mu764iLDufuMacyplcKZnUrEOp7O9dFt0z9lE+37GPubSOOL1M7g5lVGQQhO5DmnNvvnCsMvJ4JRJpZUqjqkYYlPKzs+cgzfjGEds3juHnqcq57fqmGqPCB4lJHuA4NBSVkQWBmrSzw88zM+gdqyQ9VPdIwdUpuzGs/G8Rd53Zl/vrdnPXwXKYu3qxnJDdgJaU6RxAsLy8ffQlYCJxiZnlmNt7MJprZxMAmFwKrzGwF8ChwidOZPfFAeJhx7dAOzLp5GN1aN+GOaSu54MmPWJlXEOrSxANlPQJdNRSMCK8+2Dl36XesnwRM8ur7RSpqnxTH1AkDmLZsK/e/k8OYx+dz5YB23PbDU2gcExnq8qSGlJQ6InUfQVAUm+Irx+47eP/WLH46sD0vLNrEWQ/NY9aq7brUtIHQOYLgKQjEl5o2iuTuMafy+g2DSYiNZOKLy/jxU4v4dPPeUJcm31NJaanOEQRJQSC+lpmWwFs/H8K947qzYfcBzv/bR/zPK8vZuk93JtdXR0vUIwiWgkB8LzI8jCsGtGPubVlMHJ7B259tZ8SD2dw3M4eCg0dDXZ4EqURDTARNrSUSEBcdwR0juzDnV1mc1zOFpz/cwLAH5vD3DzdQVKyH4NQXOkcQPAWBSAWpCY34y8W9mPHzofRs05R7Z+RwxoNzeXnJZopLSkNdnnwHnSMInoJApArdUprwwvjTeWF8f5IaR/Pr11Zy5kNzeXP5Vj0Ipw4r1jmCoCkIRL7D0E4teOOGQTz9k37ERIZz89TljHxEl5zWVWX3EWjXFgy1lkg1mBlndUtm5i+GMumy3hSXOia+uIzzJs1nztqdCoQ6pETnCIKmIBAJQliYMbpnCu/eMowHL+rFvoNHuXrKEi58ciEffbk71OUJxx5MoyAIhoJA5CREhIdxYd82fHBrFn88vztb9x7isqc/5vK/L2KZbkoLKfUIgqcgEPkeoiLCuPz0dmTflsX/je7G2h1f86O/fcRVUxazNFcP6AuF4tJSIjTWUFAUBCI1ICYynPFD0pl72whuP+cUPssr4MInF3LxUwuZs2anhr2uReoRBK9aQWBmcWYWFnjd2czGmJmGaxSpIC46ghuyOjL/1yP47ehubM4/yNXPLuHMh+by/MJcDhQVh7rEBu9oie4sDlZ1W2seEGNmqcD7wNXAs14VJVLfxUZFcM2QdObdPoJHLsmkcaNIfvvmagbc/z5/nPE5eXsPhrrEBqu4RDeUBau6zyMw59xBMxsPPOac+7OZfeplYSINQVREGGMzUxmbmcqyzXuZsiCXZxbk8o/5GzmjSzKZcSUMd67OPUu5Pjta6ojQfQRBqXYQmNlA4HJgfJDvFRGgT9tm9GnbjN+M7MKLizbxytItvFd4hDc3z+Pqwemc3zuVRlHhoS6z3jtaUqoH0wSpurF5C/Ab4HXn3Goz6wDM8awqkQYsJaERt5/ThQV3nMF1PaKIigjjztdXcvp97/H7t1azfmdhqEust0pKHc6hO4uDVK1f9c65ucBcgMBJ493OuV94WZhIQxcdEc7g1EjuvGwIS3L38sKiTby4aBNTFuQyuGNzfjqwPT/omqwrYIJwNDAooC4fDU61gsDM/gVMBEqAT4CmZvaQc+4BL4sT8QMzo396Iv3TE9n1dTdeXrKZf368mQkvfEJqQiOuGNCOS05Lo1lcVKhLrfOOBUGkrhoKSnVbq5tzbj8wDpgJtAWu9KooEb9q0Tiam87oxIe3j+DJK/qQltiIP81aw4D73+f2V1ewZsf+UJdYpxWXlN2voR5BcKp7wjcycN/AOGCSc+6omekOGRGPRISHcU731pzTvTVrd3zNcwtzmbYsj1eW5tG7bQIX9U2jS+vGdGvdhJhInWA+5mjpsUND6hEEo7pB8BSQC6wA5plZO0A/TURqwSmtGnPf+T247exTeG1ZHlOXbOHO11cC0Dg6grNPbcXYzBQGZTT3/Q7waKBHEKUeQVCqe7L4UeDRcos2mdkIb0oSkco0i4vi2qEdGD8knZVbC9i69xAfrNnJrNU7eG1ZHknxUZzbozVjMlPp0zbBl/cmFB4uu3M7NkpXtwejuieLmwK/A4YFFs0F/gAUeFSXiFTBzOjZJoGebRIY2aM194zrTvbaXUxfsZWpS7bw3MJNtGnWiDG9UhiTmUKXVk1CXXKt2VZwCIDWTWNCXEn9Ut3YfAZYBVwcmL8SmAL8yIuiRKT6YiLDOad7K87p3oqvDx/l3dVfMX3FNp6at4G/ZX/JKcmNGZOZwpheKaQlxoa6XE/lbC87Yp3RIj7EldQv1Q2CDOfcBeXmf29myz2oR0S+h8YxkVzQtw0X9G3D7sIi3lm5nTeXb+OB2Wt5YPZaMtMSGNa5BWMzUxrkznJlXgHtm8fqUtsgVTcIDpnZEOfcfAAzGwwc8q4sEfm+kuKjuXJge64c2J68vQd5a8V2Zq3ewaQPvuDR97+gZ5umjM1M5exuyQ2mp1Bw6ChJ8dGhLqPeqW4QTASeD5wrANgL/NSbkkSkprVpFsvPsjL4WVYGO/cfZvqKbUxbtpV73v6ce97+nFNTmjCqR2vO7dGa9klxoS73pB0pLiUqwt9XTp2M6l41tALoZWZNAvP7zewW4DMPaxMRD7RsEsO1Qztw7dAObNx9gHdX72DW6h3HDx91ahnP4I5JnNY+kdPSm9Gycf058XqkpJT4GF0xFKygWixwd/Ex/wP8tUarEZFalZ4Ux/XDM7h+eAZb9x1i1qodzFmzk5eXbOHZj3IB6J7ahB90SeasbsmcmtKkTl+WeqS4VAPOnYTvE51192+DiAQtNaER44ekM35IOkdLSlm9bT8ffbmbD3J28tgHX/DI+1/QsnE0I05pyYguLRnSKYn46Lr16/tIiQ4NnYzv839RQ0yINFCR4WFkpiWQmZbADVkdyS8sInvtLj5Yu5OZq7bz8tItRIaXDZZ3LBg6JMWFvLdwpLiUaPUIgnbCIDCzr6l8h29AI08qEpE6p3l89PHLUo+WlLI0dy9z1u5kzpqd3Dsjh3tn5JCW2Ij+7ZvTu20Cfdo2o3NyfK0PeaGTxSfnhEHgnGtcW4WISP0QGR7GwIzmDMxozp2jurJlz0Gy1+1i3rpdZK/dyWvL8gCIjQqna+sm9GqTQP/0ZvRrn+j5pZ2FRcXE1bHDVfWBWkxEvpe0xFiuHNCOKwe0wznHlj2H+HTLXpZt2svn2/fzz4838cyCjQB0SIqjd9tm9EhtwsCMJNIDl6rWxK/4ouISDh4pIaFR5Pf+LL/xLAjM7BlgNLDTOde9kvUGPAKMAg4CVznnlnlVj4h4z8xo2zyWts1jGZuZCpTtoFdtLWDxxr0syd3D3HX/7TWYQZgZ7RJjSYqPpkOLOPq1T+S09s1omxgb1DmHPQeOAJCgu4qD5mWP4FlgEvB8FetHAp0C0+nAE4H/ikgDEh0RTt92ifRtl8jPyMA5R97eQyz8Mp+N+QcwIDf/ALsLj/DOqh1MXbIFgJaNo+nTthktm0TTIj6anmkJ9EhtSmJcFAu/zOf+d3LYc+AI0RFhxESGs6PgMABdWumIdrDMOe8u/jGz9sDbVfQIngKynXMvBebXAlnOue0n+szEdl3dWXc+40W5Us6+fftISEgIdRkNntr5m5xzHDpawteHi/n6cDGFRcUUlzpKSv+7n4oIM4pLHVHhYTRpFEGpg9JSR6lzREWEVXr1ktoZXpk46BPnXL/K1oXyHEEqsKXcfF5g2beCwMwmABMAYpPT2bdvX23U52slJSVq51qgdq5cNBAdBUlRAEaJg6JiOFwCh4sd4ZGQ1MgRbsUV3llKQcG3R8dXO59YKIOgsoN/lXZPnHOTgckA/fr1c7N/PdLLugTIzs4mKysr1GU0eGrn2qF2Bruj6nWhvOA2D0grN98G2BaiWkREfCuUQTAd+ImVGQAUfNf5ARERqXleXj76EpAFJJlZHmWPuowEcM49Ccyk7NLR9ZRdPnq1V7WIiEjVPAsC59yl37HeATd69f0iIlI9GpRDRMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM95GgRmdo6ZrTWz9WZ2RyXrs8yswMyWB6bfelmPiIh8W4RXH2xm4cDjwFlAHrDEzKY75z6vsOmHzrnRXtUhIiIn5mWPoD+w3jm3wTl3BJgKjPXw+0RE5CR4GQSpwJZy83mBZRUNNLMVZvaOmZ3qYT0iIlIJzw4NAVbJMldhfhnQzjlXaGajgDeATt/6ILMJwASA5ORksrOza7ZS+ZbCwkK1cy1QO9cOtfOJeRkEeUBaufk2wLbyGzjn9pd7PdPM/mZmSc653RW2mwxMBujXr5/LysryrGgpk52djdrZe2rn2qF2PjEvDw0tATqZWbqZRQGXANPLb2BmrczMAq/7B+rJ97AmERGpwLMegXOu2MxuAmYD4cAzzrnVZjYxsP5J4ELgZ2ZWDBwCLnHOVTx8JCIiHvLy0BDOuZnAzArLniz3ehIwycsaRETkxHRnsYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicgkBExOcUBCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn1MQiIj4nIJARMTnFAQiIj6nIBAR8TkFgYiIzykIRER8TkEgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYGIiM8pCEREfE5BICLicwoCERGfUxCIiPicp0FgZueY2VozW29md1Sy3szs0cD6z8ysj5f1iIjIt3kWBGYWDjwOjAS6AZeaWbcKm40EOgWmCcATXtUjIiKV87JH0B9Y75zb4Jw7AkwFxlbYZizwvCuzCEgws9Ye1iQiIhVEePjZqcCWcvN5wOnV2CYV2F5+IzObQFmPAaDQzNbWbKlVagoU1NL7q7Ptibapal1ly6uzLAnY/R311BS1c+1QO9eOutrO7arcwjnnyQRcBPy93PyVwGMVtpkBDCk3/z7Q16uaTuLPMLm23l+dbU+0TVXrKltenWXAUrWz2lnt3LDb+djk5aGhPCCt3HwbYNtJbBNKb9Xi+6uz7Ym2qWpdZcuru6y2qJ1rh9q5dtSndgbAAolR48wsAlgH/ADYCiwBLnPOrS63zbnATcAoyg4bPeqc6+9JQRIUM1vqnOsX6joaOrVz7VA7n5hn5wicc8VmdhMwGwgHnnHOrTaziYH1TwIzKQuB9cBB4Gqv6pGgTQ51AT6hdq4daucT8KxHICIi9YPuLBYR8TkFgYiIzykIRER8TkEgQTOzcWb2tJm9aWZnh7qehsrMOpjZP8zs1VDX0tCYWZyZPRf4e3x5qOsJNQWBz5jZM2a208xWVVh+wgECy3POveGcuw64Cvixh+XWWzXUzhucc+O9rbThCLLNfwS8Gvh7PKbWi61jFAT+8yxwTvkFVQ0QaGY9zOztClPLcm+9K/A++bZnqbl2lup5lmq2OWU3rx4b3qakFmusk7wca0jqIOfcPDNrX2Hx8QECAcxsKjDWOXc/MLriZ5iZAf8PeMc5t8zjkuulmmhnCU4wbU7ZqAZtgOXoB7EaQICqB/+rys+BM4ELj90gKNUSVDubWXMzexLobWa/8bq4BqqqNp8GXGBmTxDa4SjqBPUIBMAqWVblnYbOuUeBR70rp8EKtp3zAQXt91NpmzvnDqCRDI5Tj0Cg7g/+11ConWuf2rwaFAQCZQMCdjKzdDOLAi4Bpoe4poZI7Vz71ObVoCDwGTN7CVgInGJmeWY23jlXTNkosLOBHOCV8qPESvDUzrVPbX7yNOiciIjPqUcgIuJzCgIREZ9TEIiI+JyCQETE5xQEIiI+pyAQEfE5BYE0GGZWWMvf91Etf1+Cmd1Qm98p/qAgEKmCmZ1wLC7n3KBa/s4EQEEgNU6DzkmDZmYZlI1H3wI4CFznnFtjZudR9jyFKCAfuNw595WZ3Q2kAO2B3Wa2DmgLdAj896+BQfcws0LnXLyZZQF3A7uB7sAnwBXOOWdmo4CHAuuWAR2cc98YctrMrgLOBWKAODMbA7wJNAMigbucc29SNvR3hpktB/7jnLvNzG4DLgaigdedc7+rudYT33DOadLUICagsJJl7wOdAq9PBz4IvG7Gf++svxb4S+D13ZTtyBuVm/+Ish1tEmWhEVn++4AsoICyAc3CKBvmYAhlO/YtQHpgu5eAtyup8SrKBkdLDMxHAE0Cr5OA9ZSNotkeWFXufWcDkwPrwoC3gWGh/v+gqf5N6hFIg2Vm8cAg4N9lz9IBynboULbTftnMWlPWK9hY7q3TnXOHys3PcM4VAUVmthNIpmzHXd5i51xe4HuXU7bTLgQ2OOeOffZLwIQqyv2Pc27PsdKB+8xsGFBK2fj5yZW85+zA9GlgPh7oBMyr4jtEKqUgkIYsDNjnnMusZN1jwEPOuenlDu0cc6DCtkXlXpdQ+b+byrapbCz8qpT/zsspO5TV1zl31MxyKetdVGTA/c65p4L4HpFv0cliabCcc/uBjWZ2EZQ9YtPMegVWNwW2Bl7/1KMS1gAdyj0+8cfVfF9TYGcgBEYA7QLLvwYal9tuNnBNoOeDmaXqWcdyMtQjkIYk1szKH7J5iLJf10+Y2V2UnXidCqygrAfwbzPbCiwC0mu6GOfcocDlnrPMbDewuJpv/SfwlpktpeyZumsCn5dvZgvMbBVlz4u+zcy6AgsDh74KgSuAnTX8R5EGTsNQi3jIzOKdc4VWtqd+HPjCOfdwqOsSKU+HhkS8dV3g5PFqyg756Hi+1DnqEYiI+Jx6BCIiPqcgEBHxOQWBiIjPKQhERHxOQSAi4nMKAhERn/v/PsgFI/51rBgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8f63b",
   "metadata": {},
   "source": [
    "그래프를 보고 학습률를 튜닝해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0768d4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2333 - accuracy: 0.9267 - val_loss: 0.1018 - val_accuracy: 0.9688\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0941 - accuracy: 0.9708 - val_loss: 0.0995 - val_accuracy: 0.9730\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0643 - accuracy: 0.9802 - val_loss: 0.0771 - val_accuracy: 0.9768\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0469 - accuracy: 0.9849 - val_loss: 0.0730 - val_accuracy: 0.9810\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.0680 - val_accuracy: 0.9818\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0726 - val_accuracy: 0.9798\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0775 - val_accuracy: 0.9838\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.0890 - val_accuracy: 0.9824\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0895 - val_accuracy: 0.9800\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0879 - val_accuracy: 0.9820\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1035 - val_accuracy: 0.9788\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0874 - val_accuracy: 0.9820\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0919 - val_accuracy: 0.9838\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0928 - val_accuracy: 0.9800\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0811 - val_accuracy: 0.9826\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0823 - val_accuracy: 0.9860\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 5.6057e-04 - accuracy: 0.9998 - val_loss: 0.0785 - val_accuracy: 0.9854\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 1.1999e-04 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 7.7460e-05 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9856\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 6.2582e-05 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9854\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 5.4441e-05 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9854\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.8599e-05 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9858\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.4041e-05 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.0573e-05 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9860\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.7558e-05 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9860\n"
     ]
    }
   ],
   "source": [
    "# clear_session\n",
    "# keras.backend.clear_session()\n",
    "# 현재 TF 그래프를 없애고, 새로운 TF 그래프를 만듭니다.\n",
    "#오래된 모델 혹은 층과의 혼란을 피할 때 유용합니다.\n",
    "keras.backend.clear_session()\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_last = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_last.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=3e-1),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model_last.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c95c95a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06899699568748474, 0.9814000129699707]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "284b36a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13396), started 0:29:53 ago. (Use '!kill 13396' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-350402f3ea611a96\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-350402f3ea611a96\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
