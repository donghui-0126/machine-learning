{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3843735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- conding:utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427271a7",
   "metadata": {},
   "source": [
    "이번 장에서는 자연어를 읽고 쓰는 AI를 만드는 법을 알아볼 것이다. \n",
    "\n",
    "자연어 문제를 위해 많이 사용하는 방법은 순환 신경망이다. 따라서 RNN을 계속해서 살펴본다. 문장에서 다음글자를 예측하도록 훈련하는 **문자 단위 RNN(character RNN)** 부터 시작한다. 새로운 텍스트를 생성하고 그 과정에서 매우 긴 시퀀스를 가진 텐서플로 데이터셋을 만드는 방법을 알아보자. 먼저 **상태가 없는 RNN(stateless RNN)** 을 사용하고 다음에 **상태가 있는 RNN(stateful RNN)** 을 구축할 것이다. (상태가 없는 RNN은 각 반복에서 무작위하게 택한 텍스트의 일부분으로 학습하고, 나머지 텍스트에서 어떤 정보도 사용하지 않는다. 상태가 있는 RNN은 훈련 반복 사이에 은닉 상태를 유지하고 중지된 곳에서 이어서 상태를 반영한다. 그래서 더 긴패턴을 학습할 수 있다). 그 다음에는 감성분석을 수행하는 RNN을 구축하고 이번에는 문자가 아니라 단어의 시퀀스로 문장을 다룰것이다. 그리고 신경망 기계번역(NMT)을 수행할 수 있는 인코더-디코더 구조를 만들기 위해 RNN을 사용하는 방법을 알아보자. 도구로는 텐서플로 애드온 프로젝트에서 제공하는 seq2seq API를 사용한다.\n",
    "\n",
    "16.4절에서는 어텐션 매커니즘을 알아보자. 이름에서 알 수 있듯이 이는 각 타임 스텝에서 모델이 집중해야 할 입력 부분을 선택하도록 학습하는 신경망 구성요소이다. 먼저 어텐션을 사용하여 RNN 기반의 인코더-디코더 구조의 성능을 높이는 방법을 알아본 뒤, RNN을 모두 제거하고 어텐션만 사용해 매우좋은 성능을 내는 **트랜스포머** 라는 구조도 살펴보자.  마지막으로 NLP분야에서 가장 중요한 발전을 살펴보자. 트랜스포머를 시반으로 한 GPT-2와 BERT같은 매우 강력한 언어 모델도 포함한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a1c7b",
   "metadata": {},
   "source": [
    "# char-RNN을 사용해 셰익스피어 문체 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996d1d9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11424/1419733831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mshakespear_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://homl.info/shakespear\"\u001b[0m  \u001b[1;31m# 단죽 url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shakespear.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshakespear_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mshakespear_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "shakespear_url = \"https://homl.info/shakespear\"  # 단죽 url\n",
    "filepath = keras.utils.get_file(\"shakespear.txt\", shakespear_url)\n",
    "with open(filepath) as f:\n",
    "    shakespear_text = f.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
